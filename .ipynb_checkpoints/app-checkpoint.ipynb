{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from werkzeug.wrappers import Request, Response\n",
    "from flask import Flask , render_template, request,redirect ,send_file, make_response\n",
    "import tweepy \n",
    "from tweepy.auth import OAuthHandler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import unicodedata\n",
    "import requests\n",
    "from xml.etree import ElementTree as ET\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "from scipy.stats import ttest_ind\n",
    "%matplotlib inline\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "twitter and goodreads api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitter\n",
        "ACCESS_TOKEN = \"\"\n",
    "ACCESS_TOKEN_SECRET = \"\"\n",
    "CONSUMER_KEY = \"\"\n",
    "CONSUMER_SECRET = \"\"\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "api = tweepy.API(auth , wait_on_rate_limit = True, wait_on_rate_limit_notify = True)\n",
    "\n",
    "#goodreads\n",
    "api_key = ''"
   
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets Widget URL and image URL from book title\n",
    "def getURLSfromTitle(book_title):\n",
    "    payload = {'key': api_key, 'title': book_title}\n",
    "    book_request = requests.get('https://www.goodreads.com/book/title.xml', params=payload).text\n",
    "    book_request_xml = ET.fromstring(book_request)\n",
    "    image_url = book_request_xml.find('./book/image_url').text\n",
    "    \n",
    "    widget_html = book_request_xml.find('./book/reviews_widget').text\n",
    "    widget_url = BeautifulSoup(widget_html,'html.parser').iframe['src']\n",
    "    \n",
    "    return widget_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns Reviews from URL. Ugly web scraping \n",
    "def getReviewsfromUrl(widget_url,number_pages = 10):\n",
    "    base_url = widget_url + '&num_reviews=50'\n",
    "    \n",
    "    \n",
    "    def raw_reviews_from_url(base_url,page_number):\n",
    "        \n",
    "        url = base_url + '&page=' + str(page_number)\n",
    "        reviews_html_raw = requests.get(url)\n",
    "        reviews_html = BeautifulSoup(reviews_html_raw.text,'html.parser')\n",
    "     \n",
    "        return reviews_html.findAll('div',{\"class\": \"gr_review_container\"})\n",
    "        \n",
    "        \n",
    "    def parse_review(review):\n",
    "        rating = review.find('span',{\"class\": \"gr_rating\"})\n",
    "        #user = review.find('span',{\"class\": \"gr_review_by\"})\n",
    "        comment = review.find('div',{\"class\": \"gr_review_text\"})\n",
    "        if rating and comment:\n",
    "            return rating.text,comment.text.replace('...more','').strip()\n",
    "        else:\n",
    "            return None\n",
    "         \n",
    "    raw_review_pages = [raw_reviews_from_url(base_url,page_number) for page_number in range(1,number_pages + 1)]\n",
    "    \n",
    "    review_tuples = [parse_review(review) for raw_review_page in raw_review_pages for review in raw_review_page]\n",
    "    return [review for review in review_tuples if review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-4400dad7199e>:10: SyntaxWarning: name 'data' is assigned to before global declaration\n",
      "  global data\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/' , methods =[\"POST\" , \"GET\"])\n",
    "def home():\n",
    "    if request.method =='GET' :\n",
    "        return render_template('index.html')\n",
    "\n",
    "    elif request.method ==\"POST\":\n",
    "        data=str(request.form['book_name'])\n",
    "        global data\n",
    "        return redirect('/result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets Widget URL and image URL from book title\n",
    "def getImagefromTitle(book_title):\n",
    "    payload = {'key': api_key, 'title': book_title}\n",
    "    book_request = requests.get('https://www.goodreads.com/book/title.xml', params=payload).text\n",
    "    book_request_xml = ET.fromstring(book_request)\n",
    "    image_url = book_request_xml.find('./book/image_url').text\n",
    "    \n",
    "    widget_html = book_request_xml.find('./book/reviews_widget').text\n",
    "    widget_url = BeautifulSoup(widget_html,'html.parser').iframe['src']\n",
    "    \n",
    "    return image_url#, widget_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/result\")\n",
    "def book():\n",
    "    \n",
    "    tweets = [] # SAVE the resutls of the search\n",
    "    search_terms = data ,\"read\" ,\"book\"  #change the name of the book from here\n",
    "\n",
    "    for tweet in tweepy.Cursor(api.search, q=search_terms,tweet_mode='extended').items(100):\n",
    "        tweets.append(tweet)\n",
    "        \n",
    "    # creating the datafame\n",
    "    df = pd.DataFrame(data=[tweet.full_text for tweet in tweets], columns=['text'])\n",
    "    df['id']= np.array([tweet.id for tweet in tweets])\n",
    "    df['user']= np.array([tweet.in_reply_to_screen_name for tweet in tweets])\n",
    "    df['time'] = np.array([tweet.created_at for tweet in tweets])\n",
    "    df['source'] = np.array([tweet.source for tweet in tweets])\n",
    "    df['likes'] = np.array([tweet.favorite_count for tweet in tweets])\n",
    "    df['retweets'] = np.array([tweet.retweet_count for tweet in tweets])\n",
    "    df['language'] = np.array([tweet.lang for tweet in tweets])\n",
    "    df['location'] = np.array([tweet.user.location for tweet in tweets])\n",
    "    df['polarity']=np.array([TextBlob(sen).sentiment.polarity for sen in df['text']])\n",
    "    df['subjectivity']=np.array([TextBlob(sen).sentiment.subjectivity for sen in df['text']])\n",
    "    df.drop_duplicates(subset='text', inplace = True ) # delete duplicates \n",
    "    print(df)\n",
    "    #time Chart\n",
    "    time=[]\n",
    "    for i in df['time']:\n",
    "        time.append(str(i)[:10])\n",
    "    day=(list(dict.fromkeys(time)))\n",
    "    rep=[len(list(group)) for key, group in groupby(time)]\n",
    "    \n",
    "    #Likes Chart\n",
    "    l=[]\n",
    "    for i in df['likes']:\n",
    "        l.append(str(i))\n",
    "    \n",
    "    likes=(list(dict.fromkeys(l)))\n",
    "    numl=[len(list(group)) for key, group in groupby(l)]\n",
    "    \n",
    "    #Retweets Chart\n",
    "    r=[]\n",
    "    for i in df['retweets']:\n",
    "        r.append(str(i))\n",
    "    \n",
    "    retweets=(list(dict.fromkeys(r)))\n",
    "    numr=[len(list(group)) for key, group in groupby(r)]\n",
    "        \n",
    "    #Languages Chart\n",
    "    lang=[]\n",
    "    for i in df['language']:\n",
    "        lang.append(str(i))\n",
    "    \n",
    "    language=(list(dict.fromkeys(lang)))\n",
    "    speaker=[len(list(group)) for key, group in groupby(lang)]\n",
    "    \n",
    "    #location Chart\n",
    "    location=[]\n",
    "    people=[]\n",
    "    for i in df[\"location\"].value_counts().index.tolist():\n",
    "        if len(location)<5:\n",
    "            if i!=\"\" and i!=\" \":\n",
    "                location.append(str(unicodedata.normalize('NFKD',i).encode('ascii','ignore'))[2:-1])\n",
    "                people.append(int((df['location'].values == i).sum()))\n",
    "    #sources Chart\n",
    "    source=[]\n",
    "    users=[]\n",
    "    for i in df[\"source\"].value_counts().index.tolist():\n",
    "        if len(source)<5:\n",
    "            if i!=\"\" and i!=\" \":\n",
    "                source.append(str(unicodedata.normalize('NFKD',i).encode('ascii','ignore'))[2:-1])\n",
    "                users.append(int((df['source'].values == i).sum()))\n",
    "            \n",
    "    info=[day,rep,location, people,source,users,likes,numl,retweets,numr,language,speaker]\n",
    "    #twitter embed \n",
    "    best_retweets= df.sort_values('retweets', ascending=False)\n",
    "    ide_re=[]\n",
    "    name_re=[]\n",
    "    for i in (best_retweets['id']):\n",
    "        ide_re.append(i)\n",
    "\n",
    "    for i in (best_retweets['user']):\n",
    "        name_re.append(str(i))\n",
    "    #goodreads comments\n",
    "    book_url=getURLSfromTitle(data)\n",
    "    comment=getReviewsfromUrl(book_url)\n",
    "    print (comment)\n",
    "    return render_template(\"result.html\" , data=data, img=getImagefromTitle(data),\n",
    "    total_likes=int(df.describe()[\"likes\"].max()),\n",
    "    total_retweets=int(df.describe()[\"retweets\"].max()),\n",
    "    total_tweets=df['text'].count(),\n",
    "    info=info,\n",
    "    ide_re=ide_re, name_re=name_re,\n",
    "    comment=comment)\n",
    "\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:8600/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [22/Jul/2020 08:16:43] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Jul/2020 08:16:48] \"POST / HTTP/1.1\" 302 -\n",
      "[2020-07-22 08:17:18,083] ERROR in app: Exception on /result [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wecode/.local/lib/python2.7/site-packages/flask/app.py\", line 2292, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/wecode/.local/lib/python2.7/site-packages/flask/app.py\", line 1815, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/wecode/.local/lib/python2.7/site-packages/flask/app.py\", line 1718, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/wecode/.local/lib/python2.7/site-packages/flask/app.py\", line 1813, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/wecode/.local/lib/python2.7/site-packages/flask/app.py\", line 1799, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-15-3ede86df6db3>\", line 7, in book\n",
      "    for tweet in tweepy.Cursor(api.search, q=search_terms,tweet_mode='extended').items(100):\n",
      "  File \"build/bdist.linux-x86_64/egg/tweepy/cursor.py\", line 197, in next\n",
      "    self.current_page = self.page_iterator.next()\n",
      "  File \"build/bdist.linux-x86_64/egg/tweepy/cursor.py\", line 108, in next\n",
      "    data = self.method(max_id=self.max_id, parser=RawParser(), *self.args, **self.kargs)\n",
      "  File \"build/bdist.linux-x86_64/egg/tweepy/binder.py\", line 250, in _call\n",
      "    return method.execute()\n",
      "  File \"build/bdist.linux-x86_64/egg/tweepy/binder.py\", line 192, in execute\n",
      "    six.reraise(TweepError, TweepError('Failed to send request: %s' % e), sys.exc_info()[2])\n",
      "  File \"build/bdist.linux-x86_64/egg/tweepy/binder.py\", line 190, in execute\n",
      "    proxies=self.api.proxy)\n",
      "  File \"/home/wecode/.local/lib/python2.7/site-packages/requests/sessions.py\", line 512, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/wecode/.local/lib/python2.7/site-packages/requests/sessions.py\", line 622, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/wecode/.local/lib/python2.7/site-packages/requests/adapters.py\", line 511, in send\n",
      "    raise SSLError(e, request=request)\n",
      "TweepError: Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/search/tweets.json?q=%28%27harry+potter%27%2C+%27read%27%2C+%27book%27%29&tweet_mode=extended (Caused by SSLError(SSLEOFError(8, u'EOF occurred in violation of protocol (_ssl.c:590)'),))\n",
      "127.0.0.1 - - [22/Jul/2020 08:17:18] \"GET /result HTTP/1.1\" 500 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    from werkzeug.serving import run_simple\n",
    "    run_simple('localhost', 8600, app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_36_env",
   "language": "python",
   "name": "py_36_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
